{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Lab | Chains in LangChain\n",
    "\n",
    "## Outline\n",
    "\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * SimpleSequentialChain\n",
    "  * SequentialChain\n",
    "* Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY= os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84e441b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./LAB Chains in LangChain/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7a09c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n  Â I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427e1119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\abrar\\anaconda3\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (0.3.51)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (0.3.23)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (2.6.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (0.3.31)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\abrar\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.27.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain-openai) (0.3.51)\n",
      "Collecting openai<2.0.0,>=1.68.2 (from langchain-openai)\n",
      "  Downloading openai-1.74.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.3.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\abrar\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abrar\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\abrar\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.3.12-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/61.3 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 10.2/61.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.3/61.3 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading openai-1.74.0-py3-none-any.whl (644 kB)\n",
      "   ---------------------------------------- 0.0/644.8 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/644.8 kB 3.4 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 61.4/644.8 kB 3.4 MB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 71.7/644.8 kB 787.7 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 92.2/644.8 kB 655.4 kB/s eta 0:00:01\n",
      "   ------ ------------------------------- 112.6/644.8 kB 547.6 kB/s eta 0:00:01\n",
      "   ------- ------------------------------ 122.9/644.8 kB 481.4 kB/s eta 0:00:02\n",
      "   --------- ---------------------------- 153.6/644.8 kB 484.3 kB/s eta 0:00:02\n",
      "   ---------- --------------------------- 174.1/644.8 kB 477.7 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 204.8/644.8 kB 541.9 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 235.5/644.8 kB 554.9 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 307.2/644.8 kB 593.9 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 337.9/644.8 kB 600.1 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 389.1/644.8 kB 622.1 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 399.4/644.8 kB 622.6 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 440.3/644.8 kB 641.0 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 450.6/644.8 kB 613.3 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 501.8/644.8 kB 642.5 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 532.5/644.8 kB 643.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 583.7/644.8 kB 655.4 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 614.4/644.8 kB 656.0 kB/s eta 0:00:01\n",
      "   -------------------------------------  634.9/644.8 kB 655.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 644.8/644.8 kB 634.5 kB/s eta 0:00:00\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "   ---------------------------------------- 0.0/893.9 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 71.7/893.9 kB 1.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 112.6/893.9 kB 1.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 122.9/893.9 kB 1.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 184.3/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 235.5/893.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------- --------------------------- 256.0/893.9 kB 983.0 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 307.2/893.9 kB 999.9 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 368.6/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 419.8/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 471.0/893.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 501.8/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 563.2/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 634.9/893.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 645.1/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 696.3/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 747.5/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 798.7/893.9 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 849.9/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 860.2/893.9 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- 893.9/893.9 kB 974.3 kB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken, openai, langchain-openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.66.3\n",
      "    Uninstalling openai-1.66.3:\n",
      "      Successfully uninstalled openai-1.66.3\n",
      "Successfully installed langchain-openai-0.3.12 openai-1.74.0 tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community\n",
    "! pip install -U langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e92dff22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "943237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace None by your own value and justify\n",
    "llm = ChatOpenAI(temperature=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template( #Write a query that would take a variable to describe any product\n",
    "    \"Write a short, engaging product description for the following product: {product}\"\n",
    " \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7abc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Indulge in luxury and comfort with our Queen Size Sheet Set. Made from soft, breathable fabric, this set includes a fitted sheet, flat sheet, and two pillowcases to elevate your bedroom decor. With a perfect fit for your queen size bed, you'll experience a peaceful night's sleep every time. Upgrade your bedding with our Queen Size Sheet Set and transform your bedroom into a cozy oasis.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = df['Product'].iloc[0] \n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "febee243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write an enthusiastic and engaging product description for: {input}\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Create a catchy one-line marketing tagline based on this product description: {input}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78458efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mIntroducing our luxurious Queen Size Sheet Set, the perfect addition to your bedroom oasis! Crafted from premium, ultra-soft microfiber material, these sheets are designed to provide you with the ultimate comfort and relaxation every night.\n",
      "\n",
      "Our Queen Size Sheet Set includes a flat sheet, fitted sheet, and two pillowcases to complete your bed ensemble. The deep pockets on the fitted sheet ensure a secure fit on mattresses up to 16 inches deep, while the high-quality stitching and durable fabric guarantee long-lasting use.\n",
      "\n",
      "Available in a variety of stylish colors and patterns, our Queen Size Sheet Set is sure to complement any bedroom decor. Whether you prefer classic neutrals or bold hues, we have the perfect sheets to match your style.\n",
      "\n",
      "Say goodbye to tossing and turning at night and say hello to a peaceful and restful sleep with our Queen Size Sheet Set. Treat yourself to the luxury you deserve and upgrade your bedding with our exceptional sheet set today!\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\"Sleep like royalty every night with our luxurious Queen Size Sheet Set - the perfect addition to your bedroom oasis!\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Sleep like royalty every night with our luxurious Queen Size Sheet Set - the perfect addition to your bedroom oasis!\"'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd59bda-9d02-44e7-b3d6-2bec61b99d8f",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c129ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "016187ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "  \"Translate the following product review to English:\\n\\n{review}\"\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"english_review\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0fb0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following review in 1-2 sentences:\\n\\n{english_review}\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6accf92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english or other language\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is this review written in?\\n\\n{review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c7a46121",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt template 4: follow up message that take as inputs the two previous prompts' variables\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Write a follow-up message to the customer based on this summary:\\n\\n{summary}\\n\\n\"\n",
    "        \"Also mention that their original review was written in {language}.\"\n",
    ")\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "89603117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"review\"],\n",
    "    output_variables=[\"english_review\", \"summary\", \"language\", \"followup_message\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "51b04f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': \"Je trouve le goÃ»t mÃ©diocre. La mousse ne tient pas, c'est bizarre. J'achÃ¨te les mÃªmes dans le commerce et le goÃ»t est bien meilleur...\\nVieux lot ou contrefaÃ§on !?\",\n",
       " 'english_review': \"I find the taste mediocre. The foam doesn't hold, it's strange. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\",\n",
       " 'summary': \"The reviewer finds the taste of the product mediocre and notes that the foam doesn't hold, wondering if they received an old batch or counterfeit product compared to what they usually buy in stores.\",\n",
       " 'language': 'This review is written in French.',\n",
       " 'followup_message': \"Bonjour,\\n\\nJe vous remercie d'avoir partagÃ© vos commentaires sur notre produit. Nous sommes dÃ©solÃ©s d'apprendre que vous avez trouvÃ© le goÃ»t du produit mÃ©diocre et que la mousse ne tient pas comme d'habitude. Nous prenons la qualitÃ© de nos produits trÃ¨s au sÃ©rieux et je vous assure que nous n'envoyons que des produits authentiques et frais Ã  nos clients.\\n\\nAfin de rÃ©soudre ce problÃ¨me, pourriez-vous s'il vous plaÃ®t nous fournir plus d'informations, comme le numÃ©ro de lot du produit ou des photos de l'emballage? Cela nous aidera Ã  mieux comprendre ce qui s'est passÃ© et Ã  prendre les mesures nÃ©cessaires pour y remÃ©dier.\\n\\nNous vous remercions encore une fois pour vos commentaires et vous prions de nous excuser pour tout inconvÃ©nient causÃ©. Nous espÃ©rons pouvoir vous fournir une expÃ©rience plus satisfaisante Ã  l'avenir.\\n\\nCordialement,\\n\\n[L'Ã©quipe du service clientÃ¨le]\"}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187cf07-458a-4226-bec7-3dec7ee47af2",
   "metadata": {},
   "source": [
    "**Repeat the above twice for different products or reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ade83f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "biology_template = \"\"\"You are an excellent biologist. \\\n",
    "You have a deep understanding of living organisms, \\\n",
    "from the molecular and cellular level to entire ecosystems. \\\n",
    "You are skilled at observing patterns in nature, analyzing biological data, \\\n",
    "and explaining complex processes like evolution, genetics, physiology, and ecology. \\\n",
    "You can clearly communicate how life functions and adapts, \\\n",
    "and you make connections between different biological concepts \\\n",
    "to answer challenging questions.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5f590e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"biology\",\n",
    "        \"description\": \"Good for answering biology questions\",\n",
    "        \"prompt_template\": biology_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "31b06fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3f50bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8eefec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9f98018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11b2e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1387109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2fb7d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d86b2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the electromagnetic radiation emitted by a perfect black body, which is an idealized physical body that absorbs all incident electromagnetic radiation and emits radiation at all frequencies. The radiation emitted by a black body depends only on its temperature and follows a specific distribution known as Planck's law. This type of radiation is important in understanding concepts such as thermal radiation and the behavior of objects at different temperatures.\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b717379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to 2 + 2 is 4.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29e5be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'Why does every cell in our body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Every cell in our body contains DNA because DNA is the genetic material that carries the instructions for the development, functioning, and reproduction of all living organisms. DNA contains the information needed to build and maintain an organism, including the proteins that make up our cells and tissues. \\n\\nHaving DNA in every cell ensures that each cell has the necessary genetic information to carry out its specific functions and to replicate itself accurately during cell division. This genetic information is crucial for maintaining the integrity and stability of our cells and for passing on genetic traits to future generations. \\n\\nAdditionally, DNA is constantly being replicated and repaired in our cells to ensure that genetic information is accurately transmitted from one generation of cells to the next. This process helps to prevent errors and mutations that could lead to diseases or abnormalities. \\n\\nIn summary, every cell in our body contains DNA because it is essential for the proper functioning and development of all living organisms.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c60b-7ae0-453e-9467-142d8dafee6e",
   "metadata": {},
   "source": [
    "**Repeat the above at least once for different inputs and chains executions - Be creative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "59e7d5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: How did Ada Lovelace contribute to computer science?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "computer science: {'input': 'How did Ada Lovelace contribute to computer science?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: Ada Lovelace, often referred to as the world's first computer programmer, made significant contributions to the field of computer science. She worked closely with Charles Babbage, the inventor of the Analytical Engine, a mechanical general-purpose computer. Lovelace translated and annotated an article on the Analytical Engine written by Italian mathematician Luigi Federico Menabrea, adding her own insights and notes that included what is now considered the first algorithm intended to be processed by a machine. This algorithm is often cited as the first computer program ever written.\n",
      "\n",
      "Lovelace's work laid the foundation for modern computer programming and her visionary ideas about the potential of computers went far beyond the capabilities of the technology of her time. She recognized that computers could be used for more than just mathematical calculations and envisioned a future where computers could create music, art, and even help in scientific research.\n",
      "\n",
      "Overall, Ada Lovelace's contributions to computer science were groundbreaking and her work continues to inspire and influence the field to this day.\n",
      "============================================================\n",
      "User Query: Explain how chloroplasts help plants survive.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'Explain how chloroplasts help plants survive.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: Chloroplasts are essential organelles found in plant cells that play a crucial role in the survival of plants. These specialized structures are responsible for photosynthesis, the process by which plants convert sunlight into energy in the form of glucose.\n",
      "\n",
      "During photosynthesis, chloroplasts use sunlight, carbon dioxide, and water to produce glucose and oxygen. This glucose serves as the primary source of energy for the plant, fueling various metabolic processes necessary for growth, development, and reproduction. Additionally, oxygen is released as a byproduct of photosynthesis, which is essential for respiration in plants and other organisms.\n",
      "\n",
      "In addition to producing energy, chloroplasts also help plants survive by regulating their internal environment. They are involved in the synthesis of various compounds, such as pigments and hormones, that are important for plant growth and defense against environmental stressors. Chloroplasts also play a role in the storage and recycling of nutrients, helping plants adapt to changing conditions and maintain their overall health.\n",
      "\n",
      "Overall, chloroplasts are vital for the survival of plants as they provide the energy and resources necessary for growth, development, and adaptation to their environment. Without these organelles, plants would not be able to photosynthesize and would struggle to thrive in their ecosystems.\n",
      "============================================================\n",
      "User Query: What were the causes and effects of the Cold War?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "History: {'input': 'What were the causes and effects of the Cold War?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: The Cold War was a period of geopolitical tension between the United States and its allies on one side, and the Soviet Union and its allies on the other, following World War II. The causes of the Cold War can be traced back to a number of factors, including ideological differences between capitalism and communism, competition for global influence and power, and the legacy of mistrust and suspicion stemming from World War II.\n",
      "\n",
      "One of the key effects of the Cold War was the division of the world into two opposing blocs, with the United States leading the Western capitalist bloc and the Soviet Union leading the Eastern communist bloc. This division led to the proliferation of proxy wars, espionage, and arms races, as both sides sought to gain an advantage over the other.\n",
      "\n",
      "The Cold War also had a significant impact on the global economy, as both superpowers engaged in a costly arms race that diverted resources away from social programs and economic development. Additionally, the Cold War led to the establishment of military alliances such as NATO and the Warsaw Pact, which further solidified the division of the world into opposing camps.\n",
      "\n",
      "Overall, the Cold War had far-reaching consequences for global politics, economics, and society, shaping the world order for decades to come.\n",
      "============================================================\n",
      "User Query: What is the integral of e^x?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'What is the integral of e^x?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: The integral of e^x is simply e^x + C, where C is the constant of integration.\n",
      "============================================================\n",
      "User Query: Can you explain string theory to a child?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'Can you explain string theory to a child?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: String theory is a theory in physics that suggests that the fundamental building blocks of the universe are tiny, vibrating strings. These strings can vibrate in different ways, creating different particles like electrons and quarks. Think of it like the strings on a guitar vibrating to create different notes. String theory is still being studied and researched by scientists to better understand how the universe works.\n",
      "============================================================\n",
      "User Query: How does recursion work in programming?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "computer science: {'input': 'How does recursion work in programming?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: Recursion in programming is a technique where a function calls itself in order to solve a problem. When a function is called recursively, it breaks down the problem into smaller subproblems until a base case is reached, at which point the function stops calling itself and returns a value. \n",
      "\n",
      "Recursion works by dividing a problem into smaller, more manageable subproblems, and then combining the solutions to these subproblems to solve the original problem. This process continues until the base case is reached, which is a condition that determines when the recursion should stop.\n",
      "\n",
      "Recursion is commonly used in programming for tasks such as traversing data structures (like trees or graphs), searching algorithms (like binary search), and mathematical calculations (like factorial or Fibonacci sequence). \n",
      "\n",
      "It is important to note that recursion can be a powerful tool in programming, but it can also be tricky to implement correctly. It is essential to ensure that the base case is properly defined and that the recursive calls eventually lead to the base case to avoid infinite loops. Additionally, recursion can sometimes be less efficient than iterative solutions, as it can consume more memory due to the function call stack. \n",
      "\n",
      "Overall, recursion is a valuable technique in programming that can simplify complex problems and make code more elegant and concise when used appropriately.\n",
      "============================================================\n",
      "User Query: What happens during mitosis?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'What happens during mitosis?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: During mitosis, a cell undergoes a series of stages to divide its nucleus and genetic material into two identical daughter cells. The process can be divided into four main stages: prophase, metaphase, anaphase, and telophase.\n",
      "\n",
      "1. Prophase: During prophase, the chromatin in the nucleus condenses into visible chromosomes. The nuclear envelope breaks down, and the mitotic spindle, made of microtubules, begins to form.\n",
      "\n",
      "2. Metaphase: In metaphase, the chromosomes line up along the metaphase plate, an imaginary plane in the center of the cell. The spindle fibers attach to the centromeres of each chromosome, ensuring they are properly aligned.\n",
      "\n",
      "3. Anaphase: Anaphase is characterized by the separation of sister chromatids. The spindle fibers pull the chromatids apart towards opposite poles of the cell. Once separated, each chromatid is considered a full-fledged chromosome.\n",
      "\n",
      "4. Telophase: During telophase, the chromosomes reach the opposite poles of the cell and begin to decondense back into chromatin. The nuclear envelope reforms around each set of chromosomes, and the spindle fibers disassemble.\n",
      "\n",
      "Finally, cytokinesis occurs, where the cytoplasm of the cell is divided, resulting in two separate daughter cells, each with an identical set of chromosomes. This process ensures that each daughter cell receives a complete and identical copy of the genetic material from the parent cell.\n",
      "============================================================\n",
      "User Query: Describe the Big Bang theory in simple terms.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'Describe the Big Bang theory in simple terms.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: The Big Bang theory is the scientific explanation for how the universe began. It states that about 13.8 billion years ago, all matter and energy in the universe was concentrated into a single point, or singularity, and then suddenly expanded outward in a massive explosion. This expansion continues to this day, with galaxies moving away from each other. The Big Bang theory is supported by evidence such as the cosmic microwave background radiation and the redshift of galaxies.\n",
      "============================================================\n",
      "User Query: What's the best pizza topping according to math?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': \"What's the best pizza topping according to math?\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: As a mathematician, I would approach this question by considering the preferences of a large group of people and using statistical analysis to determine the most popular pizza topping. I would gather data on the frequency of different toppings chosen by individuals and calculate the mean, median, and mode to determine the most commonly preferred topping. Additionally, I could use mathematical models such as regression analysis to identify any correlations between toppings and overall satisfaction. Ultimately, the best pizza topping according to math would be the one that is most frequently chosen and consistently leads to high levels of satisfaction among pizza eaters.\n",
      "============================================================\n",
      "User Query: Do birds know quantum physics?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "biology: {'input': 'Do birds know quantum physics?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: As a biologist, I can confidently say that birds do not have an understanding of quantum physics. Quantum physics is a highly complex and abstract field of study that deals with the behavior of particles at the smallest scales. Birds, like all animals, operate based on their instincts, learned behaviors, and sensory perceptions to navigate their environment, find food, and reproduce. While birds may exhibit some remarkable abilities such as navigation using Earth's magnetic field or complex mating rituals, these behaviors are not based on an understanding of quantum physics.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Repeat the router chain execution with different creative inputs\n",
    "creative_inputs = [\n",
    "    \"How did Ada Lovelace contribute to computer science?\",\n",
    "    \"Explain how chloroplasts help plants survive.\",\n",
    "    \"What were the causes and effects of the Cold War?\",\n",
    "    \"What is the integral of e^x?\",\n",
    "    \"Can you explain string theory to a child?\",\n",
    "    \"How does recursion work in programming?\",\n",
    "    \"What happens during mitosis?\",\n",
    "    \"Describe the Big Bang theory in simple terms.\",\n",
    "    \"What's the best pizza topping according to math?\",  # Should go to default\n",
    "    \"Do birds know quantum physics?\"  # Should go to default\n",
    "]\n",
    "\n",
    "# Execute each input through the chain\n",
    "for input_query in creative_inputs:\n",
    "    print(f\"User Query: {input_query}\")\n",
    "    response = chain.run(input_query)\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
